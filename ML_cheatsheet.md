<details>
<summary> ### 机器学习实战第二版  </summary>
**有监督：** K近邻、线性回归、逻辑回归、支持向量机SVM、决策树和随机森林、神经网络  
**无监督：** 聚类、K均值、DBSCAN、分层聚类HCA、异常检测和新颖性检测、单类SVM、孤立森林、可视化和降维、主成分分析、核主成分分析、局部线性嵌入LLE、关联规则学习、Apriori、Eclat  
**半监督：** 深度信念网络（DBN）基于一种互相堆叠的无监督组件，这个组件叫作受限玻尔兹曼机（RBM）。受限玻尔兹曼机以无监督方式进行训练，然后使用有监督学习技术对整个系统进行微调  
**强化学习** 智能体  
**批量学习** 离线学习，更新数据的同时，也要重新训练  
**增量学习** 在线学习，但是不一定是实时。适应大数据量的训练任务。适应不断变化的数据的速度：学习率  
数据庞大时另一种方法：选择Map reduce技术，跨多个服务器拆分进行批处理学习  
>在线学习面临的一个重大挑战是，如果给系统输入不良数据，系统
的性能将会逐渐下降。现在某些实时系统的客户说不定已经注意到了这
个现象。不良数据的来源可能是机器上发生故障的传感器，或者是有人
对搜索引擎恶意刷屏以提高搜索结果排名等。为了降低这种风险，你需
要密切监控系统，一旦检测到性能下降，就及时中断学习（可能还需要
恢复到之前的工作状态）。当然，同时你还需要监控输入数据，并对异
常数据做出响应（例如，使用异常检测算法）。
> 
**机器学习面临的问题** 训练数据不足、训练数据不具有代表性（泛化能力）、训练数据包含异常和噪声、无关特征  
>过拟合：收集更多的训练数据、减少模型的参数（增加正则化超参数）、修复数据中的错误和消除异常值  
>欠拟合：提供更好的特征、增加模型的参数、减少正则化超参数
>
**机器学习流程**
明确任务、数据挖掘、数据分析、数据预处理、选择并训练模型、微调模型、展示解决方案、系统上线  
</details>

### 机器学习知识点
1、模型：想要学习的条件概率分布或者决策函数；具体来说就是模型结构，比如CNN、RNN、LSTM、transformer；  
策略：从假设空间中选出参数最优的模型的准则，比如损失函数最小；比如均方差、交叉熵  
算法：如何求解全局最优解，比如优化算法：SGF、Adam  
2、归纳偏置：关于目标函数的必要假设  
3、逻辑回归处理的是分类问题，线性回归处理的是回归问题  
logit函数：对数几率函数  
几率=p/(1-p)  
![image](https://github.com/zhangwenjingustb/LookForWork/assets/141011729/da9487cb-d925-448f-b765-ea361fa86322)  
![image](https://github.com/zhangwenjingustb/LookForWork/assets/141011729/5aceed6a-572e-4948-acc0-79d84496ede7)  
逻辑回归：对特征加权求和，输入给sigmoid函数，输出概率，决定二分类的结果  
4、支持向量机  
寻找一个超平面，使得不同类别的数据到超平面的间隔（几何间隔）最大。  
函数间隔：在超平面w*\x+b=0确定的情况下，|w\*x+b|能够表示点x到距离超平面的远近，而通过观察w\*x+b的符号与类标记y的符号是否一致可判断分类是否正确，可以用(y\*(w\*x+b))的正负性来判定或表示分类的正确性。  
函数间隔=(y\*(w\*x+b))  
几何间隔就是函数间隔除以||w||，而且函数间隔y*(wx+b) = y*f(x)实际上就是|f(x)|，只是人为定义的一个间隔度量，而几何间隔|f(x)|/||w||才是直观上的点到超平面的距离。  
![image](https://github.com/zhangwenjingustb/LookForWork/assets/141011729/a0f22922-4354-442a-a6f7-badbcabb2407) ![image](https://github.com/zhangwenjingustb/LookForWork/assets/141011729/6a504cff-1047-4c74-93dd-18ec934f9b1b)  
![image](https://github.com/zhangwenjingustb/LookForWork/assets/141011729/40bcb04e-30aa-4c71-a053-52ac73b6f6fd)  









